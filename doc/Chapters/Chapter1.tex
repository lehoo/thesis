% Chapter 1

\chapter{Introduction}
\label{Chapter1}
\lhead{Chapter 1. \emph{Introduction}}

Distributed computing is a very important concept in computer
science. There are multiple types of large-scale distributed
environments that can be used for either production purposes or for
research. Parallelism is also used in a lower level, for example in
graphics processing, where we can have multiple graphics chips in one
computer to do the task.\\[0.3cm]
When doing distributed computing, communication between the processes
becomes a very important concern, since it can pose a relatively large
overhead compared to sequential problem-solving. To make parallelism
worthwhile, we have to make sure that the speedup provided by the
distribution of tasks makes up for the communication overhead. There
are two important factors to take into account when trying to
achieve this: task distribution needs to be carefully planned and the
communication protocols are needed to be optimized. Focusing on the
latter, a widely utilized communication protocol that has been under
development for many years
is provided by the MPI\cite{mpif12} inter-process, language-independent
communication API. MPI itself is just a specification, which has
multiple existing implementations. The most widely used ones include
OpenMPI\cite{ompi04} and MPICH\cite{glds96}\cite{gl96}.\\[0.3cm]
There are various reasons to why simulation, and particularly that of
large-scale computing systems has become a very
important field of research and a favored direction to go in for
scientists. Setting up a distributed environment is a complicated
endeavour: it needs both human and monetary resources. Such an
investment and commitment to one system might not be feasible - we may
only need it to run a few experiments. There is the option of renting
resources, but that also comes with extra expenses. Also, when doing
research in distributed computing, our needs possibly exceed the use
of just one single platform: we would like to test how our experiments
fare on multiple different environments. Another reason is that
sometimes we would like to predict what a given system would be
capable of, so we are fully aware of its capabilities before acquiring
it, making sure it has the attributes we need.\\[0.3cm]
SimGrid\cite{clq08} is a project providing a wide range of features
regarding simulation: it is a scientific instrument that can be
used to simulate large-scale distributed systems in order to study
their behavior by evaluating and analyzing the results of parallel
experiments run with the simulator. As mentioned before, inter-process
communication is a very important concern for these experiments. SMPI
is a framework that is part of the SimGrid project. This framework
makes it possible to simulate the execution of parallel applications
that use the MPI standard, with the simulation happening on a single
node.\\[0.3cm]
SMPI is a framework that has been validated in the past by experiment
results. Such results have been documented and published, for example
in \cite{csgscq11}. Results are needed to be reproducible, by
providing that the conducted experiments are repeatable. However,
currently, the testing process to procure such results
consists of multiple steps, many of them being manual configuration
steps, such as the allocating of nodes, the creation of a file
containing the allocated nodes or the distribution of the benchmark's
runnable between the nodes. These tedious test processes lack a
universal, user-friendly guide which could help other researchers in
reproducing the
acquired results in order to do further validation. Such a guide would
also help in repurposing, extending our experiments by changing
parameters, switching the underlying configuration, etc. Providing the
possibility to easily repeat the experiments conducted for a paper
is very important: our goal when writing a paper is not only to
announce our results but also to convince our readers that our results
are correct.\cite{m10} The best way to prove that we are right is if
we provide a straightforward way for anyone to repeat our experiments,
so they can see for themselves that our results stand. Also, if other
scientists are unable to repeat our experiments, that means that they
are unable to incorporate our results in their research (which may or
may not be related to our field). This would the main point of
scientific collaboration and as such, should be facilitated as much as
possible.\\[0.3cm]
SMPI is a well-documented and working framework, but also an active
project. It is also a project with the goal of applying simulation to
study large scale computing systems, which is a relatively new
concept. As such, the project is under constant
development. Currently, a lot of resources are spent on developing
generic network models for
the simulator. Extensive testing is needed for the development
process, since continuous validation is necessary to see whether or
not we are heading in the right direction, whether or not the
simulator correctly represents the real-world behavior. This
testing process, as previously mentioned, is currently very
time-consuming. This doesn't only limit the number of tests that can
be run, but also limits the reproducibility of the
results that are achieved with SMPI, the importance of which has been
discussed in the previous paragraph. By constructing a framework that
simplifies the testing process, more reliable and verifiable results
could be produced, as well as it would make the SMPI project members'
lives easier. It is important to include as much automation in the
framework as possible, since other researchers that want to repeat the
experiments might not be computer experts. Our processes can't be
fully automated though. For example, certain parameters, such as the
runnable, or the number of nodes to allocate have to be set - but,
when doing the implementation, we aim to keep such non-automated steps
minimal.\\[0.3cm]
This thesis discusses how such a framework could be built and provides
an implementation, utilizing the XPflow\cite{bn12_2} experimentation
engine. XPflow is a fairly new project, constantly under development.
Although it hasn't been officially released yet, it's fairly stable
and suitable for our project. It's designed to help automating
experiments, utilizing a top-down approach taken from business
workflows.\\[0.3cm]
With the implementation, our main goals are to make testing faster and
more efficient by providing a way to automate the process. Linking
together multiple different MPI experiments could further help
speeding up the course of getting results. Another
important goal is to take the burden of doing the currently
repetitive, error-prone process over and over again off the developers
in the SimGrid team. The framework can also prove to be a means to
have a better organization of tests - separate test files could be
written and stored in their respective directories, categorized
according to what they can be used for, instead of the current
on-the-fly manual process.\\[0.3cm]
The thesis is organized in the following way. In Chapter 2, we go over
research material connected to the thesis subject, citing relevant
documents. In Chapter 3, we examine various aspects of the problem
that the implementation of the framework poses. While Chapter 3 is
more of a general problem description, Chapter 4 is about specifics,
implementation details of the framework. Then in Chapter 5, we
discuss the process of evaluating the framework, which will be done by
running the same experiment in the "old", manual way and with the
framework. In the same chapter, we observe how the actual evaluation
goes, observing the steps in both cases, then citing the numerical
results. In the end of the chapter, we compare these results, as well
as the two methodologies to get to a conclusion whether or not we
reached our goals. Then finally, in Chapter 6, we conclude the thesis
with a summary of the content, and in the end, we take a look at what
the possible directions for development are for the project.
